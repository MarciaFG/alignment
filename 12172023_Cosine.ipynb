{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPkMBMevIlzRq9fP8OKu+BB"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7VMi1PuCNN8",
        "outputId": "df49cbbb-257d-403f-d2c6-9720eee86dc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n",
            "Your runtime has 13.6 gigabytes of available RAM\n",
            "\n",
            "To enable a high-RAM runtime, select the Runtime → \"Change runtime type\"\n",
            "menu, and then select High-RAM in the Runtime shape dropdown. Then, \n",
            "re-execute this cell.\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime → \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('To enable a high-RAM runtime, select the Runtime → \"Change runtime type\"')\n",
        "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "  print('re-execute this cell.')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "print('Authenticated')"
      ],
      "metadata": {
        "id": "upwqQoBID0TC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Loading the datasets\n",
        "import pandas as pd\n",
        "\n",
        "PATH = '/content/drive/My Drive/revisions_natcomms/data/DATASET.csv'\n",
        "\n",
        "data = pd.read_csv(PATH, delimiter=';')\n",
        "\n",
        "NEW = data.loc[(data['Newcomer'] == 1) & (data['LR_main_field_id']== 'Biomedical and health sciences')]\n",
        "OUT = data.loc[(data['Outgoer'] == 1) & (data['LR_main_field_id']== 'Biomedical and health sciences')]\n",
        "NAT = data.loc[(data['Native'] == 1) & (data['LR_main_field_id'] == 'Biomedical and health sciences')]"
      ],
      "metadata": {
        "id": "wcLb-_MWD16x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%% FUNCTIONS TO CREATE AUTHOR-INSTITUTION TOPICS' MATRIX\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "from networkx.algorithms import bipartite\n",
        "\n",
        "def create_df(path):\n",
        "    #import data\n",
        "    df = pd.read_csv(path, header=None, sep=';')\n",
        "    df.drop([3], axis=1, inplace=True)\n",
        "    df.columns = ['aut', 'ins', 'sk']\n",
        "    return df\n",
        "\n",
        "def create_matrix(df):\n",
        "    print(1)\n",
        "    #get author-institution and skills list\n",
        "    aut_list = list(df.aut)\n",
        "    ins_list = list(df.ins)\n",
        "    sk_list = list(df.sk)\n",
        "    aut_ins_list = [x+'__'+y for x,y in zip(aut_list, ins_list)]\n",
        "    unique_aut_ins = np.unique(aut_ins_list).tolist()\n",
        "    unique_sk = np.unique(sk_list).tolist()\n",
        "    print(2)\n",
        "    #create bipartite graph\n",
        "    df_edges = pd.DataFrame(list(zip(aut_ins_list, sk_list)), columns=['aut_ins', 'sk'])\n",
        "    df_edges.to_csv('edge_list.edgelist', sep=' ', header=False, index=False)\n",
        "    G = bipartite.read_edgelist(\"edge_list.edgelist\")\n",
        "    unique_sk = [str(x) for x in unique_sk]\n",
        "    M_as = bipartite.biadjacency_matrix(G, row_order = unique_aut_ins, column_order = unique_sk)\n",
        "    G.clear()\n",
        "    nodes_ins = [x.partition('__')[2] for x in unique_aut_ins]\n",
        "    nodes_ins = np.array(nodes_ins)\n",
        "    unique_ins = np.unique(nodes_ins)\n",
        "    return M_as, unique_sk, nodes_ins"
      ],
      "metadata": {
        "id": "yW9m1NoBWTp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Biomedical and health sciences"
      ],
      "metadata": {
        "id": "9NgQXbcnXCQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%%GET AUTHOR-INSTITUTION SKILLS MATRIX FOR RESIDENTS AND OUTGOINGS\n",
        "\n",
        "df = create_df('C:/Documents/sci_mobility/homophily_adaptation/datasets/shuffle/residents.csv')\n",
        "M_res_as, unique_sk_res, nodes_ins_res = create_matrix(df)\n",
        "\n",
        "df = create_df('C:/Documents/sci_mobility/homophily_adaptation/datasets/shuffle/outgoers.csv')\n",
        "M_out_as, unique_sk_out, nodes_ins_out = create_matrix(df)\n",
        "\n",
        "#%%GET MAPPINGS FROM NODES TO UNIQUE_INS\n",
        "unique_ins = np.unique(nodes_ins_out)\n",
        "\n",
        "ins2nodes_res = {}\n",
        "for i, x in enumerate(unique_ins):\n",
        "    print(i)\n",
        "    idx = np.where(nodes_ins_res == x)[0]\n",
        "    ins2nodes_res[x] = idx\n",
        "\n",
        "ins2nodes_out = {}\n",
        "for i, x in enumerate(unique_ins):\n",
        "    print(i)\n",
        "    idx = np.where(nodes_ins_out == x)[0]\n",
        "    ins2nodes_out[x] = idx"
      ],
      "metadata": {
        "id": "q0jRDF50W4Ww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QTnr8dhWUym1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}